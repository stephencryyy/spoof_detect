# Архитектура и логика работы Python gRPC сервиса в проекте RealTone

## 1. Введение

**RealTone** — это полностековое приложение, предназначенное для высокоточного обнаружения подделок (дипфейков) в аудиофайлах. Система использует передовые модели машинного обучения для глубокого анализа звука.

Архитектура проекта включает несколько ключевых компонентов:

*   **Go REST API Сервис**: Основная точка входа для клиентских приложений (например, фронтенда). Отвечает за прием запросов, аутентификацию, управление задачами анализа и взаимодействие с другими сервисами.
*   **Python gRPC Сервис**: Специализированный сервис, отвечающий за ресурсоемкую задачу анализа аудиофайлов с использованием ML-модели.
*   **Базы данных и хранилища**:
    *   **MinIO**: S3-совместимое хранилище для аудиофайлов.
    *   **PostgreSQL**: Реляционная база данных для хранения метаданных, статусов задач и результатов анализа.
    *   **Redis**: Хранилище данных в памяти, используемое для временного хранения аудиочанков.

Данный документ подробно описывает устройство и логику работы Python gRPC сервиса, его взаимодействие с Go REST API и причины выбора используемых технологий.

## 2. Python gRPC Сервис (Анализ Аудио)

### Назначение

Основная задача Python gRPC сервиса — выполнение вычислительно интенсивного анализа аудиофайлов для обнаружения признаков подделки. Это включает предобработку аудио, применение ML-модели и формирование результатов.

### Почему gRPC?

Для взаимодействия между Go REST API и Python-сервисом анализа был выбран gRPC по следующим причинам:

*   **Эффективность**: gRPC использует Protocol Buffers (Protobuf) для сериализации данных. Protobuf — это бинарный формат, который компактнее и быстрее, чем текстовые форматы вроде JSON, используемые в REST. Также gRPC работает поверх HTTP/2, который предлагает мультиплексирование, сжатие заголовков и другие оптимизации, снижающие задержки и повышающие пропускную способность.
*   **Строгая типизация и контракт**: Определение сервисов и сообщений в `.proto` файлах создает четкий контракт между клиентом (Go) и сервером (Python). Это упрощает разработку, уменьшает вероятность ошибок интеграции и позволяет автоматически генерировать клиентский и серверный код на разных языках.
*   **Поддержка потоковой передачи**: gRPC нативно поддерживает различные типы потоковой передачи (серверная, клиентская, двунаправленная). Хотя в текущей реализации основной ответ не потоковый, эта возможность может быть полезна для будущих расширений (например, передача результатов по мере их готовности для очень длинных аудио).
*   **Идеально для межсервисного взаимодействия**: gRPC хорошо подходит для создания производительных и надежных API для коммуникации между микросервисами внутри системы.

### Ключевые файлы и их логика

#### `proto/audio_analyzer.proto`

Этот файл определяет контракт gRPC сервиса:

*   **`package audioanalyzer;`**: Имя пакета для генерируемого кода.
*   **`service AudioAnalysis`**: Определяет сам сервис.
    *   **`rpc AnalyzeAudio (AnalyzeAudioRequest) returns (AnalyzeAudioResponse);`**: Единственный метод сервиса. Он принимает `AnalyzeAudioRequest` и возвращает `AnalyzeAudioResponse`.
*   **`message AnalyzeAudioRequest`**: Сообщение-запрос, содержащее:
    *   `minio_bucket_name`: Название бакета в MinIO, где хранится аудиофайл.
    *   `minio_object_key`: Ключ (путь) к аудиофайлу в указанном бакете.
*   **`message AudioChunkPrediction`**: Сообщение для детализации предсказания по каждому аудиочанку:
    *   `chunk_id`: Идентификатор чанка (например, "chunk\_0").
    *   `score`: Оценка вероятности спуфинга (0-1).
    *   `start_time_seconds`, `end_time_seconds`: Временные метки начала и конца чанка.
*   **`message AnalyzeAudioResponse`**: Сообщение-ответ, содержащее:
    *   `repeated AudioChunkPrediction predictions`: Список предсказаний для каждого чанка аудиофайла.
    *   `error_message`: Строка с описанием ошибки, если анализ не удался.

#### `server/grpc_server.py`

Этот файл содержит реализацию Python gRPC сервера:

*   **Класс `AudioAnalysisServicer(audio_analyzer_pb2_grpc.AudioAnalysisServicer)`**: Наследуется от сгенерированного базового класса и реализует логику сервиса.
*   **`__init__(self)` (Конструктор)**:
    *   Определяет устройство для вычислений (`cuda` или `cpu`).
    *   Загружает ML-модель с помощью функции `load_model_from_checkpoint` из `inference.py`.
    *   Инициализирует клиент для подключения к Redis.
    *   Инициализирует клиент для подключения к MinIO, используя учетные данные из переменных окружения.
*   **Метод `AnalyzeAudio(self, request: AnalyzeAudioRequest, context)`**: Основной метод, обрабатывающий запрос на анализ.
    1.  **Получение данных из запроса**: Извлекает `minio_bucket_name` и `minio_object_key`.
    2.  **Проверки**: Убеждается в доступности Redis и MinIO клиента.
    3.  **Скачивание файла из MinIO**: Использует `minio_client` для загрузки аудиофайла по указанным в запросе bucket и key.
    4.  **Нарезка аудио на чанки**: Аудиофайл делится на более короткие сегменты (чанки) фиксированной длительности (`NUM_SAMPLES / SAMPLE_RATE` секунд). Эта логика реализована в приватном методе `_slice_audio_into_chunks` (его полный код не представлен в контексте, но предполагается, что он выполняет нарезку и, возможно, сохраняет чанки в Redis, как указано в `WhatNeed.md` и функции `_process_chunk_from_redis`).
    5.  **Обработка каждого чанка (через Redis)**: Для каждого чанка, идентификатор которого был получен после нарезки:
        *   Вызывается метод `_process_chunk_from_redis`. Этот метод:
            *   Загружает данные чанка из Redis по ключу (например, `internal_request_id_for_redis:chunk_0`).
            *   Преобразует байты чанка в тензор.
            *   Выполняет предсказание для тензора чанка с помощью `_predict_score_for_chunk_tensor`, который внутри вызывает ML-модель.
            *   Формирует объект `AudioChunkPrediction` с результатом.
    6.  **Формирование ответа**: Собирает все `AudioChunkPrediction` в список.
    7.  **Возврат результата**: Отправляет `AnalyzeAudioResponse`, содержащий список предсказаний или сообщение об ошибке.

#### `server/inference.py`

Этот файл содержит всю логику, связанную непосредственно с ML-моделью и ее применением:

*   **Константы**: `MODEL_CHECKPOINT` (имя предобученной модели из Hugging Face), `SAMPLE_RATE` (целевая частота дискретизации), `NUM_SAMPLES` (количество семплов в одном чанке, определяет его длительность), `CHECKPOINT_FILE` (имя файла с весами дообученной модели).
*   **Класс `CustomWavLMForClassification(nn.Module)`**: Определяет архитектуру ML-модели. Использует предобученную модель WavLM (`microsoft/wavlm-base`) и добавляет к ней слои для задачи классификации (пулинг и линейный слой).
*   **Функция `load_model_from_checkpoint(checkpoint_path, device)`**: Загружает веса модели из указанного файла чекпоинта (`.pth`) в инициализированный экземпляр `CustomWavLMForClassification`.
*   **Функция `preprocess_audio_bytes(audio_bytes, target_sr, num_samples)`**: Выполняет предобработку аудио, поданного в виде байтового потока:
    1.  Загружает аудио из байтов с помощью `torchaudio.load`.
    2.  Ресемплирует аудио до `target_sr` (16000 Гц).
    3.  Конвертирует аудио в моно.
    4.  Обрезает или дополняет нулями (паддинг) аудио до требуемой длины `num_samples` (4 секунды).
*   **Функция `predict_audio_bytes(audio_bytes, model, device)`**: Принимает байты аудио, модель и устройство. Вызывает `preprocess_audio_bytes`, подготавливает тензор и передает его в модель для получения предсказания (логита). Затем применяет сигмоиду к логиту для получения вероятности.
*   **Глобальная инициализация модели**: При запуске скрипта (или при импорте и вызове `initialize_model`) модель загружается один раз, чтобы избежать повторной загрузки при каждом запросе.

### Взаимодействие с другими компонентами

*   **Go REST API**: Python gRPC сервис получает от него запросы на анализ аудио.
*   **MinIO**: Читает исходные аудиофайлы, указанные в запросе от Go.
*   **Redis**: Используется для временного хранения нарезанных аудиочанков. Python-сервис сначала нарезает весь файл, сохраняет чанки в Redis, а затем последовательно (или параллельно, если бы архитектура была другой) читает каждый чанк из Redis для обработки моделью.

## 3. Go REST API Сервис

### Назначение

Go REST API выступает в роли фасада и оркестратора всей системы:

*   **Точка входа**: Принимает HTTP-запросы от клиентов (например, веб-фронтенда).
*   **Управление файлами**: Обрабатывает загрузку аудиофайлов от пользователей.
*   **Оркестрация анализа**: Инициирует процесс анализа, взаимодействуя с Python gRPC сервисом.
*   **Управление задачами**: Отслеживает статус задач анализа.
*   **Хранение результатов**: Сохраняет результаты анализа.
*   **Аутентификация и авторизация**: (Предполагается) Управляет доступом пользователей.

### Почему REST API?

Для клиентского API (взаимодействие с фронтендом или внешними системами) был выбран REST по следующим причинам:

*   **Широкая распространенность**: RESTful API являются стандартом де-факто для веб-сервисов, поддерживаются всеми языками программирования и фреймворками.
*   **Простота использования**: HTTP методы (GET, POST, PUT, DELETE) и статусные коды интуитивно понятны.
*   **Бесстатусные запросы**: Каждый запрос содержит всю необходимую информацию, что упрощает масштабирование.
*   **Поддержка JSON**: JSON является легковесным и человекочитаемым форматом данных, удобным для веб-приложений.

### Логика работы (согласно `WhatNeed.md`)

1.  **Загрузка файла**: Клиент отправляет аудиофайл на специальный эндпоинт Go REST API.
2.  **Сохранение в MinIO**: Go-сервис загружает полученный файл в MinIO и получает ключ объекта.
3.  **Создание задачи в PostgreSQL**: Go-сервис создает запись в таблице истории анализа в PostgreSQL. Эта запись включает уникальный `task_id`, информацию о файле (ключ в MinIO), статус (например, `PENDING` или `PROCESSING`) и другие метаданные.
4.  **Асинхронный вызов Python gRPC**: Go-сервис **в новой горутине** (чтобы не блокировать основной HTTP-ответ) отправляет gRPC запрос методу `AnalyzeAudio` Python-сервиса. В запросе передаются `minio_bucket_name` и `minio_object_key`.
5.  **Немедленный HTTP-ответ клиенту**: Сразу после запуска горутины и создания задачи, Go-сервис отвечает клиенту `HTTP 202 Accepted` и возвращает `task_id`.
6.  **Ожидание ответа от Python**: Горутина в Go-сервисе ожидает ответ от Python gRPC сервиса.
7.  **Обновление задачи в PostgreSQL**: После получения ответа (результатов анализа или ошибки) от Python, горутина обновляет соответствующую запись в PostgreSQL: изменяет статус (например, на `COMPLETED` или `ERROR`) и сохраняет предсказания или сообщение об ошибке.
8.  **Получение статуса/результата**: Клиент может использовать другой эндпоинт Go REST API, передавая `task_id`, чтобы запросить текущий статус и результаты анализа. Go-сервис читает эту информацию из PostgreSQL.

## 4. Базы Данных и Хранилища

### MinIO (S3-совместимое хранилище объектов)

*   **Назначение**: Долговременное хранение оригинальных аудиофайлов, загруженных пользователями.
*   **Почему MinIO?**
    *   **S3-совместимость**: Предоставляет API, совместимый с Amazon S3, что является отраслевым стандартом. Это обеспечивает наличие большого количества клиентских библиотек и инструментов.
    *   **Масштабируемость**: Позволяет хранить большие объемы данных и легко масштабируется.
    *   **Надежность**: Обеспечивает сохранность данных.
    *   **Отделение данных от приложения**: Файлы хранятся отдельно от кода приложения, что упрощает управление и бэкапы.
    *   **Self-hosted**: Можно развернуть на собственных серверах, что дает полный контроль над данными.

### PostgreSQL (Реляционная СУБД)

*   **Назначение**: Хранение структурированных данных, таких как:
    *   Информация о пользователях (если есть аутентификация).
    *   Метаданные загруженных аудиофайлов (имя файла, дата загрузки, пользователь и т.д.).
    *   Задачи на анализ (`task_id`, статус обработки, ссылки на файл в MinIO).
    *   Результаты анализа (предсказания по чанкам, общее заключение).
*   **Почему PostgreSQL?**
    *   **Надежность и ACID**: Гарантирует целостность данных благодаря поддержке транзакций (ACID).
    *   **Гибкость SQL**: Мощный язык запросов SQL позволяет выполнять сложные выборки и агрегации данных.
    *   **Поддержка JSON/JSONB**: Позволяет эффективно хранить и индексировать полуструктурированные данные, такие как результаты предсказаний (которые представляют собой карту или список объектов).
    *   **Расширяемость**: Имеет множество расширений для различных нужд.
    *   **Open Source**: Свободно распространяемое ПО с активным сообществом.

### Redis (In-memory data store)

*   **Назначение**: Временное хранение нарезанных аудиочанков. Python gRPC сервис, после скачивания полного аудиофайла из MinIO, нарезает его на чанки. Эти чанки помещаются в Redis. Затем сервис читает каждый чанк из Redis для последующей обработки ML-моделью.
*   **Почему Redis?**
    *   **Высокая скорость**: Redis хранит данные в оперативной памяти, что обеспечивает очень быстрый доступ (чтение и запись).
    *   **Простота**: Легко использовать для кэширования и как временное хранилище.
    *   **Структуры данных**: Поддерживает различные структуры данных (строки, списки, хэши и т.д.), что удобно для организации временных данных.
    *   **Снижение нагрузки**: Использование Redis для чанков позволяет избежать многократного чтения из более медленного хранилища (если бы чанки обрабатывались полностью независимо) или сохранения множества мелких временных файлов на диске Python-сервера.
    *   **TTL (Time To Live)**: Возможность устанавливать время жизни для ключей позволяет автоматически удалять устаревшие чанки, предотвращая переполнение памяти.

## 5. Общая схема взаимодействия

1.  **Клиент (Фронтенд)** загружает аудиофайл через **Go REST API**.
2.  **Go REST API** сохраняет файл в **MinIO**.
3.  **Go REST API** создает запись о задаче в **PostgreSQL** со статусом "в ожидании" и генерирует `task_id`.
4.  **Go REST API** (асинхронно, в горутине) отправляет gRPC запрос с `minio_bucket_name` и `minio_object_key` на **Python gRPC Сервис**.
5.  **Go REST API** немедленно отвечает клиенту `HTTP 202 Accepted` с `task_id`.
6.  **Python gRPC Сервис** получает запрос.
7.  **Python gRPC Сервис** скачивает аудиофайл из **MinIO**.
8.  **Python gRPC Сервис** нарезает аудио на чанки и сохраняет их в **Redis**.
9.  **Python gRPC Сервис** для каждого чанка:
    *   Читает чанк из **Redis**.
    *   Выполняет анализ с помощью **ML-модели**.
10. **Python gRPC Сервис** агрегирует результаты и отправляет gRPC ответ (предсказания или ошибку) обратно в горутину **Go REST API**.
11. Горутина **Go REST API** получает ответ.
12. **Go REST API** обновляет запись в **PostgreSQL** (статус "завершено/ошибка", сохраняет результаты).
13. **Клиент** может периодически запрашивать статус/результат по `task_id` у **Go REST API**.
14. **Go REST API** читает данные из **PostgreSQL** и возвращает их клиенту.

## 6. Заключение

Выбранная архитектура с разделением на Go REST API для клиентского взаимодействия и оркестрации, и Python gRPC сервис для интенсивных вычислений, позволяет эффективно использовать сильные стороны каждого языка и технологии:

*   **Go**: Отлично подходит для создания высокопроизводительных сетевых приложений, обработки параллельных запросов и управления состоянием.
*   **Python**: Обладает богатой экосистемой для машинного обучения и анализа данных.
*   **gRPC**: Обеспечивает эффективное и типизированное межсервисное взаимодействие.
*   **REST API**: Предоставляет стандартный и удобный интерфейс для клиентов.
*   **MinIO, PostgreSQL, Redis**: Каждое хранилище используется для той задачи, для которой оно лучше всего подходит (хранение объектов, структурированных данных, кэширование).

Такое разделение ответственности способствует лучшей масштабируемости, сопровождаемости и позволяет командам разработчиков (если они разные) работать более независимо над своими частями системы.