# Python gRPC Audio Analysis Service for Spoof Detection

Этот сервис является Python-компонентом в распределенной системе детекции аудио дипфейков. 
Он реализован как gRPC сервер, который принимает запросы на анализ аудиофайлов, хранящихся в MinIO, 
обрабатывает их с помощью ML-модели (WavLM) и возвращает предсказания по чанкам.

## Архитектура и Взаимодействие

Python gRPC сервис разработан для асинхронной работы с вышестоящим Go-сервисом (REST API).

1.  **Go REST API** (не часть этого репозитория):
    *   Принимает аудиофайл от пользователя.
    *   Загружает файл в **MinIO**.
    *   Сохраняет метаданные о задаче в **PostgreSQL** (включая `task_id`, путь к файлу в MinIO, статус).
    *   Асинхронно (в горутине) отправляет gRPC запрос этому Python-сервису.
    *   Немедленно отвечает пользователю (например, HTTP 202 Accepted + `task_id`).

2.  **Python gRPC Сервис** (данный компонент):
    *   Принимает gRPC запрос `AnalyzeAudioRequest` от Go-сервиса. Запрос содержит:
        *   `minio_bucket_name`: Имя бакета в MinIO.
        *   `minio_object_key`: Ключ (путь) к аудиофайлу в указанном бакете.
    *   Скачивает указанный аудиофайл из **MinIO**.
    *   **Предобработка аудио**: Конвертирует аудио в WAV PCM, 16 бит, 16 кГц, моно.
    *   **Нарезка на чанки**: Делит аудио на непересекающиеся чанки по 4 секунды.
    *   **Кэширование чанков в Redis**: Каждый аудио-чанк сохраняется в Redis для временного хранения перед обработкой моделью. Это также может быть полезно для повторной обработки или отладки.
    *   **Параллельный инференс**: Для каждого чанка (извлеченного из Redis) параллельно выполняется предсказание с использованием ML-модели (WavLM).
    *   Модель возвращает `score` (от 0.0 до 1.0) для каждого чанка, где 0.0 - "очень вероятно настоящий", 1.0 - "очень вероятно фейк".
    *   Формирует gRPC ответ `AnalyzeAudioResponse`, содержащий:
        *   `predictions`: Карта (map) `string -> float`, где ключ - идентификатор чанка (например, `"chunk_0"`), а значение - предсказанный `score`.
        *   `error_message`: Сообщение об ошибке, если что-то пошло не так во время обработки.
    *   Отправляет ответ обратно Go-сервису.

3.  **Go REST API** (продолжение):
    *   Горутина, получившая ответ от Python-сервиса, обновляет статус задачи и сохраняет предсказания в **PostgreSQL**.
    *   (Опционально) Уведомляет пользователя о завершении задачи (например, через WebSockets).

**Стек технологий Python-сервиса:**
*   **gRPC**: для межсервисного взаимодействия с Go.
*   **Python**: язык реализации.
*   **PyTorch**: для работы с ML-моделью.
*   **Transformers (Hugging Face)**: для загрузки и использования предобученной модели WavLM.
*   **Torchaudio**: для операций с аудио (загрузка, ресемплинг, конвертация в моно).
*   **MinIO Client (`minio`)**: для взаимодействия с объектным хранилищем MinIO.
*   **Redis Client (`redis`)**: для кэширования аудио-чанков.
*   **NumPy**: для работы с числовыми данными.

## Структура проекта (Python-часть)

```
.
├── proto/
│   └── audio_analyzer.proto  # Определение gRPC сервиса и сообщений
├── server/
│   ├── audio_analyzer_pb2.py      # Сгенерированный Python-код из .proto (сообщения)
│   ├── audio_analyzer_pb2_grpc.py # Сгенерированный Python-код из .proto (клиент и сервер)
│   ├── grpc_server.py             # Основной файл gRPC сервера, логика обработки
│   ├── inference.py               # Логика загрузки модели, предобработки и инференса
│   ├── chk.pth                    # Пример файла чекпоинта модели (ЗАМЕНИТЕ НА ВАШ)
│   └── test_client.py             # Тестовый gRPC клиент для проверки сервера
└── README.md                      # Этот файл
```

## Настройка и Запуск

### 1. Предварительные требования

*   **Python** (рекомендуется версия 3.9+).
*   **Pip** (менеджер пакетов Python).
*   **MinIO сервер**: Запущен и доступен. У вас должны быть эндпоинт, ключ доступа, секретный ключ и имя бакета.
*   **Redis сервер**: Запущен и доступен (по умолчанию `localhost:6379`).
*   **Файл чекпоинта модели**: Файл с весами вашей обученной модели (например, `chk.pth`) должен находиться в директории `server/` или путь к нему должен быть корректно указан в `server/inference.py` (константа `CHECKPOINT_FILE`).

### 2. Установка зависимостей

В корневой директории проекта (или в директории `server/`, если вы предпочитаете держать зависимости там) создайте и активируйте виртуальное окружение:

```bash
python -m venv .venv
# Для Windows (PowerShell):
.venv\Scripts\Activate.ps1
# Для Linux/macOS:
source .venv/bin/activate
```

Установите необходимые Python-библиотеки:

```bash
# Находясь в активированном окружении
# Основные зависимости для gRPC, модели и аудио
pip install grpcio grpcio-tools torch torchaudio transformers numpy
# Клиенты для MinIO и Redis
pip install minio redis
```

### 3. Генерация gRPC кода (если вы меняли `.proto` файл)

Если вы внесли изменения в `proto/audio_analyzer.proto`, перегенерируйте Python-код:

```bash
# Находясь в корневой директории проекта
python -m grpc_tools.protoc -I./proto --python_out=./server --grpc_python_out=./server ./proto/audio_analyzer.proto
```

### 4. Настройка переменных окружения

Перед запуском `server/grpc_server.py`, необходимо установить следующие переменные окружения для подключения к MinIO и Redis:

*   **Для MinIO:**
    *   `MINIO_ENDPOINT`: Эндпоинт вашего MinIO сервера (например, `localhost:9000`).
    *   `MINIO_ACCESS_KEY`: Ваш ключ доступа к MinIO.
    *   `MINIO_SECRET_KEY`: Ваш секретный ключ к MinIO.
    *   `MINIO_SECURE`: Установите `True`, если ваше MinIO соединение использует HTTPS, иначе `False` (по умолчанию `False`).

*   **Для Redis (опционально, если отличается от значений по умолчанию):**
    *   `REDIS_HOST`: Хост Redis (по умолчанию `localhost`).
    *   `REDIS_PORT`: Порт Redis (по умолчанию `6379`).

**Пример установки переменных окружения (Linux/macOS):**
```bash
export MINIO_ENDPOINT="localhost:9000"
export MINIO_ACCESS_KEY="your_access_key"
export MINIO_SECRET_KEY="your_secret_key"
export MINIO_SECURE="False"
```
**Пример установки переменных окружения (Windows PowerShell):**
```powershell
$env:MINIO_ENDPOINT = "localhost:9000"
$env:MINIO_ACCESS_KEY = "your_access_key"
$env:MINIO_SECRET_KEY = "your_secret_key"
$env:MINIO_SECURE = "False"
```

### 5. Запуск gRPC сервера

Убедитесь, что ваше виртуальное окружение активировано и все переменные окружения установлены.

```bash
# Находясь в корневой директории проекта
python server/grpc_server.py
```

Сервер должен запуститься и вывести сообщения о загрузке модели, подключении к Redis и MinIO, а также о прослушивании порта (по умолчанию `[::]:50052`).

### 6. Тестирование сервера (опционально, с помощью `test_client.py`)

Тестовый клиент `server/test_client.py` позволяет отправить запрос на сервер для проверки его работоспособности.

1.  **Подготовьте тестовый файл в MinIO**:
    *   Убедитесь, что ваш MinIO сервер запущен.
    *   Создайте бакет (если его еще нет).
    *   Загрузите в этот бакет тестовый аудиофайл.

2.  **Настройте `test_client.py`**:
    *   Откройте файл `server/test_client.py`.
    *   Измените значения констант `TEST_MINIO_BUCKET_NAME` и `TEST_MINIO_OBJECT_KEY` так, чтобы они соответствовали вашему тестовому файлу в MinIO.

3.  **Запустите `test_client.py`** (в отдельном терминале, с активированным виртуальным окружением):
    ```bash
    # Находясь в корневой директории проекта
    python server/test_client.py
    ```

    Клиент отправит запрос, а в его консоли и в консоли сервера вы увидите логи обработки и результат.

## Основные компоненты кода

*   **`server/grpc_server.py`**: 
    *   `AudioAnalysisServicer`: Класс, реализующий gRPC сервис.
        *   `__init__()`: Инициализация модели, Redis клиента, MinIO клиента.
        *   `AnalyzeAudio()`: Основной метод, обрабатывающий gRPC запросы. Включает скачивание из MinIO, предобработку аудио, нарезку на чанки, сохранение/получение чанков из Redis, параллельный запуск инференса для каждого чанка.
        *   `_process_chunk_from_redis()`: Вспомогательный метод для обработки одного чанка.
        *   `_predict_score_for_chunk_tensor()`: Выполняет инференс для тензора чанка.
    *   `serve()`: Функция для запуска gRPC сервера.

*   **`server/inference.py`**: (Предполагается, что этот файл существует и содержит)
    *   `CustomWavLMForClassification`: Класс вашей ML-модели.
    *   `load_model_from_checkpoint()`: Функция для загрузки весов модели из файла чекпоинта.
    *   Константы `MODEL_CHECKPOINT`, `SAMPLE_RATE`, `NUM_SAMPLES`, `CHECKPOINT_FILE`.
    *   Функции предобработки аудио (если они там).

## Дальнейшие возможные доработки

*   **Улучшенное логирование**: Использование модуля `logging` вместо `print()`.
*   **Более гибкая конфигурация**: Использование `.env` файлов или конфигурационных файлов (YAML, JSON).
*   **Метрики для Prometheus**: Интеграция с `prometheus_client` для сбора метрик производительности.
*   **Unit-тесты и интеграционные тесты**.
*   **Обработка `task_id`**: Если Go-сервис будет передавать `task_id`, его можно использовать для более детального логирования и, возможно, для формирования ключей в Redis.